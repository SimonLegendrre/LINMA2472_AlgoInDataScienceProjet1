{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=6  color=#003366> [LINMA 2472] - ALGORITHMS IN DATA SCIENCE <br><br> \n",
    "HW 2 (Part I): k-PCA for outlier detection!   </font> <br><br><br>\n",
    "\n",
    "<font size=5  color=#003366>\n",
    "\n",
    "\n",
    "<br><br>\n",
    "Lo√Øc Van Hoorebeeck [LVH]  (loic.vanhoorebeeck@uclouvain.be)<br> <br>\n",
    "<div style=\"text-align: right\"> Version 1 (2021-10-27)</div>\n",
    "\n",
    "<br><br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "<font size=7 color=#009999> Assignment 1. PCA vs. k-PCA <br><br> for outlier detection </font> <br>\n",
    "\n",
    "<br>\n",
    "<font size=5 color=#009999> Contex </font> <br>\n",
    "\n",
    "In this assignment, you are asked to compare PCA vs. KPCA (or k-PCA) for outlier detection. We define an outlier as any point sampled from another distribution than the one we are interested in.\n",
    "\n",
    "\n",
    "\n",
    "<font size=5 color=#009999> Instruction </font> <br>\n",
    "\n",
    "You should fill the jupyter notebook, and write a written report that answers the questions from the pdf file.\n",
    "\n",
    "You have to submit <b> 3 </b> files on moodle:\n",
    "\n",
    "    - Your jupyter notebook as .ipynb \n",
    "    - Your jupyter notebook (with all output, that is after running everything) as .pdf\n",
    "    - Your written report as .pdf\n",
    "    \n",
    "Note that we filled the notebook such that it runs without throwing errors... But we had to sometimes write dummy lines, which implies that the plots look also dummy.\n",
    "\n",
    "When you have to modify something in the code, you'll find a \"TODO\" mark.\n",
    "\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Various import\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.decomposition import PCA, KernelPCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "# When developping code, it is often easier to work with a fixed seed\n",
    "np.random.seed(42)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> Q1. IMPORT THE DATA and perform EDA</font> <br>\n",
    "\n",
    "The data consists in two arrays $X \\in \\mathbb{R}^{N \\times 2}$ and $\\mathbf{y} \\in \\mathbb{R}^{N}$ with\n",
    "\n",
    "$$\n",
    "y_i =\n",
    "\\begin{cases}\n",
    "    1 & \\text{ if } & \\mathbf{X}_{i, *} & \\text{ is an outlier,}\\\\\n",
    "    0 & \\text{ if } & \\mathbf{X}_{i, *} & \\text{ is a true point.}\n",
    "\\end{cases}\n",
    "$$\n",
    "\n",
    "with $N$ the number of samples. There are $N_o$ outliers and $N_t$ *true* point, that is $N_t$ points that are not outliers.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import of the data\n",
    "\n",
    "X = np.loadtxt('X.txt')\n",
    "y = np.loadtxt('y.txt').astype(int)\n",
    "\n",
    "# TODO\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> Q2. Perform the splits </font> <br>\n",
    "\n",
    "</font>\n",
    "\n",
    "No need to reimplent the wheel: use <a href='https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html'><code>train_test_split</code></a> from sklearn to perform the splits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train = X\n",
    "X_val = X\n",
    "X_test = X\n",
    "\n",
    "y_train = X\n",
    "y_val = X\n",
    "y_test = X\n",
    "\n",
    "# TODO\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> Q3. PCA </font> <br>\n",
    "</font>\n",
    "\n",
    "Let us implement an outlier detector using PCA. In order to make our life easier, we will create a class, denoted as <code>OutlierDetectorPCA</code>, that inherits from other classes of <code>sklearn</code>.\n",
    "\n",
    "We implemented most of the class, but there are some parts missing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator, ClassifierMixin, RegressorMixin\n",
    "from sklearn.utils.validation import check_X_y, check_array, check_is_fitted\n",
    "\n",
    "plt.rcParams['figure.figsize'] = [20, 10]\n",
    "\n",
    "\n",
    "class OutlierDetectorPCA(BaseEstimator, ClassifierMixin):\n",
    "    def __init__(self, k):\n",
    "        \"\"\" ------------------------------------------------------------------------------\n",
    "        Class constructor\n",
    "        INPUT:\n",
    "            - k: the number of eigenvectors that we keep, or equivalently, the size of the\n",
    "                 the eigen (sub)space.\n",
    "        ------------------------------------------------------------------------------ \"\"\"\n",
    "\n",
    "        self.k = k\n",
    "        self.is_fitted_ = False\n",
    "        self.pca = PCA()\n",
    "        self.name = 'PCA'\n",
    "        self.pca = PCA()\n",
    "        self.tau = np.inf\n",
    "\n",
    "  \n",
    "    def _get_recons_error(self, X, X_hat):\n",
    "        \"\"\" ------------------------------------------------------------------------------\n",
    "        Compute the reconstruction error between X and X_hat, where X_hat is the projection \n",
    "        of X onto the k-dimensional eigenspace\n",
    "        INPUT: \n",
    "            - X: initial features\n",
    "            - X_hat: projected features\n",
    "        OUTPUT:\n",
    "            - recons_error: the reconstruction error\n",
    "        ------------------------------------------------------------------------------ \"\"\"\n",
    "\n",
    "        recons_error = np.ones(X.shape[0])\n",
    "        \n",
    "        return recons_error\n",
    "\n",
    "    def _predict_tau_ROC(self, X, tau):\n",
    "        \"\"\" ------------------------------------------------------------------------------\n",
    "        Companion function used to properly deal with the inheritance\n",
    "        ------------------------------------------------------------------------------ \"\"\"\n",
    "        return self.predict_tau(X, tau)    \n",
    "    \n",
    "    \n",
    "    def fit(self, X, y=None):\n",
    "        \"\"\" ------------------------------------------------------------------------------\n",
    "        Fit the model to the true data\n",
    "        INPUT: \n",
    "            - X: train data\n",
    "            - y: label data\n",
    "        OUTPUT:\n",
    "            - the classifier\n",
    "        ------------------------------------------------------------------------------ \"\"\"\n",
    "        \n",
    "        # We find the index of true data, i.e., not the outliers\n",
    "        \n",
    "        idx = np.where(y==0)[0]\n",
    "        \n",
    "\n",
    "        X_true = X[idx, :]\n",
    "        \n",
    "        # In this (supervised) context, it is better to fit PCA on the true data\n",
    "        self.pca.fit(X_true)\n",
    "        \n",
    "        # X_pca stands for X expressed in the PCA basis\n",
    "        X_pca = self.pca.transform(X_true)\n",
    "        \n",
    "        # X_hat_pca is the projection of X_pca on the eigenspace of dimension k\n",
    "        # this is done by selecting the k first principal components\n",
    "        X_hat_pca = X_pca[:, :self.k]\n",
    " \n",
    "        \n",
    "        recons_error = self._get_recons_error(X_pca, X_hat_pca)\n",
    "        \n",
    "        self.is_fitted_ = True\n",
    "\n",
    "        \"\"\"\n",
    "            TODO: compute tau such that\n",
    "                - No true data will be labeled as outlier in the training set\n",
    "                - The false positive rate (FPR) is minimized\n",
    "        \"\"\"\n",
    "        self.tau = 42\n",
    "        \n",
    "        self.tau_max = self.tau # Do not change this line :-)\n",
    "\n",
    "        return self\n",
    "\n",
    "\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\" ------------------------------------------------------------------------------\n",
    "        Predict the data using the fitted model\n",
    "        INPUT: \n",
    "            - X: data\n",
    "        OUTPUT:\n",
    "            - y: predictions\n",
    "        ------------------------------------------------------------------------------ \"\"\"\n",
    "        \n",
    "        # Sanity checks\n",
    "        check_is_fitted(self)\n",
    "        X = check_array(X)\n",
    "        \n",
    "        y = self.predict_tau(X, self.tau)\n",
    "        return y\n",
    "\n",
    "    def get_label(self):\n",
    "        label = \"{name}: k={k}\".format(name=self.name, k=self.k)\n",
    "        return label\n",
    "\n",
    "\n",
    "    def get_ROC(self, X_train, y_train):\n",
    "        \"\"\" ------------------------------------------------------------------------------\n",
    "        Compute the quantities needed to plot the ROC\n",
    "        INPUT: \n",
    "            - X_train: data of the train set\n",
    "            - y_train: label of the train set\n",
    "        OUTPUT:\n",
    "            - FPR: False positive rate\n",
    "            - TPR: True positive rate\n",
    "        ------------------------------------------------------------------------------ \"\"\"\n",
    "        n_tau = 100\n",
    "        taus = np.linspace(0, self.tau, n_tau)\n",
    "        \n",
    "        TPR = np.empty(n_tau+1)\n",
    "        FPR = np.empty(n_tau+1)\n",
    "        N = np.count_nonzero(y_train)\n",
    "        P = len(y_train) - N\n",
    "\n",
    "        for i, _t in enumerate(taus):\n",
    "            x_detec = self._predict_tau_ROC(X_train, _t)\n",
    "            TPR[i] = np.sum(np.logical_and(x_detec, y_train))/N\n",
    "            FPR[i] = np.sum(np.logical_and(x_detec, np.logical_not(y_train)))/P\n",
    "\n",
    "        # One last time for tau_max that may change during the prediction...\n",
    "        x_detec = self._predict_tau_ROC(X_train, self.tau_max)\n",
    "        TPR[-1] = np.sum(np.logical_and(x_detec, y_train))/N\n",
    "        FPR[-1] = np.sum(np.logical_and(x_detec, np.logical_not(y_train)))/P        \n",
    "            \n",
    "        return FPR, TPR\n",
    "             \n",
    "    \n",
    "    def predict_tau(self, X, tau):\n",
    "        \"\"\" ------------------------------------------------------------------------------\n",
    "        Predict the data using the fitted model with a given treshold tau\n",
    "        INPUT: \n",
    "            - X: data, nd.array of shape (n_samples, n_features)\n",
    "            - tau: treshold\n",
    "        OUTPUT:\n",
    "            - y: binary predictions, nd.array of shape (n_samples,)\n",
    "            \n",
    "        If the reconstruction error of X[i, :] is:\n",
    "                - greater than tau: y[i] = 1 (outlier detection)\n",
    "                - smaller or equal than tau: y[i] = 0         \n",
    "        ------------------------------------------------------------------------------ \"\"\"\n",
    "        \n",
    "        # TODO\n",
    "                \n",
    "        y_pred = np.ones(X.shape[0])\n",
    "\n",
    "        return y_pred   \n",
    "    \n",
    "    \n",
    "    def score(self, X_val, y_val):\n",
    "        \"\"\" ------------------------------------------------------------------------------\n",
    "        Compute the score on some test set\n",
    "        INPUT: \n",
    "            - X: input\n",
    "            - y: label\n",
    "        OUTPUT:\n",
    "            - score: the ratio of \"hit\", (TP+TN)/(P+N)\n",
    "        ------------------------------------------------------------------------------ \"\"\"      \n",
    "        \n",
    "        # TODO\n",
    "        recons_error =  np.ones_like(y_val) # change this line accordingly\n",
    "        score = 1.0\n",
    "        \n",
    "        \n",
    "        self.tau_max = max(self.tau, max(recons_error)) # Do not change this line :-)\n",
    "\n",
    "        return score\n",
    "\n",
    "    def transform(self, X):\n",
    "        return self.pca.transform(X)\n",
    "   \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helping functions for visualisation, nothing TODO here,\n",
    "# but you may have a look and/or change anything (but use comments!).\n",
    "\n",
    "def plot_ROC(classifs, X_train, y_train, file_name=None):\n",
    "    \"\"\" ------------------------------------------------------------------------------\n",
    "    Plot the ROC of classifiers.    \n",
    "    INPUT:\n",
    "        - classifs: either a single classifier, or a list of classifiers\n",
    "        - X_train: train data\n",
    "        - y_train: train label\n",
    "        - file_name: name of the file to be saved\n",
    "\n",
    "        - save: boolean, whether we save or not the fig\n",
    "    OUTPUT:\n",
    "        - plot the ROC of the different classifiers in classifs\n",
    "        - if file_name is not None, save as file_name.pdf\n",
    "    ------------------------------------------------------------------------------ \"\"\"    \n",
    "    if not isinstance(classifs, list):\n",
    "        classifs = [classifs]\n",
    "    fig, ax = plt.subplots()\n",
    "    for classif in classifs:\n",
    "        FPR, TPR = classif.get_ROC(X_train, y_train)\n",
    "        label = classif.get_label() \n",
    "            \n",
    "        ax.plot(FPR, TPR, label=label)\n",
    "    ax.set_xlabel('False Positive Rate', fontsize=14)\n",
    "    ax.set_ylabel('True Positive Rate', fontsize=14)\n",
    "    ax.plot([0, 1], [0, 1], '--', label = 'random classifier')\n",
    "    ax.scatter(0, 1, marker='o', color='green', label='Perfect classifier')\n",
    "    ax.legend(fontsize=14, loc='center left', bbox_to_anchor=(1, 0.5))\n",
    "    if file_name:\n",
    "        plt.savefig(file_name+'.pdf', bbox_inches='tight')\n",
    "        \n",
    "\n",
    "def plot_comparison_outlier_detector(list_clf, X_avail, y_avail, file_name=None):\n",
    "    \"\"\" ------------------------------------------------------------------------------\n",
    "    Plot the regions where the classifier output an outlier (in green) or not (in purple)\n",
    "    for two classifiers.\n",
    "    INPUT: \n",
    "        - list_clf: List of classifiers\n",
    "        - X_avail: data\n",
    "        - y_avail: label\n",
    "        - file_name: name of the file to be saved\n",
    "    OUTPUT:\n",
    "        - plot of the different classification regions\n",
    "        - if file_name is not None, save as file_name.pdf\n",
    "    ------------------------------------------------------------------------------ \"\"\"\n",
    "\n",
    "    plt.figure()\n",
    "    n_clf = len(list_clf)\n",
    "    \n",
    "    plt.rcParams['figure.figsize'] = [20, 10*(n_clf//2+1)]\n",
    "\n",
    "    n_outlier = np.count_nonzero(y_avail)\n",
    "    \n",
    "    t = np.linspace(-20, 20, 50)\n",
    "    X1, X2 = np.meshgrid(t, t)  \n",
    "    cmap = plt.get_cmap('PiYG')\n",
    "    \n",
    "    for n, clf in enumerate(list_clf):\n",
    "        plt.subplot(n_clf//2+1, 2, n+1)\n",
    "        plt.title(\"({name})\".format(name=clf.get_label()), wrap=True, fontsize=14)\n",
    "\n",
    "        blues = np.arange(X_avail.shape[0]-n_outlier)\n",
    "        reds = np.arange(X_avail.shape[0]-n_outlier, X_avail.shape[0])\n",
    "\n",
    "        plt.xlabel(\"$x_1$\")\n",
    "        plt.ylabel(\"$x_2$\")\n",
    "\n",
    "        X_grid = np.array([np.ravel(X1), np.ravel(X2)]).T\n",
    "\n",
    "        P_grid_PCA = clf.predict(X_grid.reshape((-1,2))).reshape(X1.shape)\n",
    "        plt.tight_layout() # Or equivalently,  \"plt.tight_layout()\"\n",
    "        plt.pcolormesh(X1, X2, P_grid_PCA, cmap=cmap, shading='auto')\n",
    "        plt.colorbar()\n",
    "        plt.scatter(X[blues, 0], X[blues, 1],\n",
    "                s=20, edgecolor='k', c=X[blues, 0])\n",
    "\n",
    "        plt.scatter(X[reds, 0], X[reds, 1],\n",
    "                s=20, edgecolor='k', c='red')\n",
    "\n",
    "    if file_name:\n",
    "        plt.savefig(file_name+'.pdf', bbox_inches='tight')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# TODO: you may test here your implementation of the class OutlierDetectorPCA\n",
    "\n",
    "# Stupid example\n",
    "k = 1\n",
    "clf_pca = OutlierDetectorPCA(k)\n",
    "clf_pca.fit(X, y)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> Q4. k-PCA </font> <br>\n",
    "</font>\n",
    "\n",
    "Let us implement an outlier detector using <b>k-PCA</b>.\n",
    "We can now leverage the work we did by defining a class in Q3: we \"cheat\" by <b>computing the features of the feature space</b> and then applying standard PCA on it.\n",
    "\n",
    "We implemented most of the class, but there are some parts missing..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-warning\">\n",
    "    <b>[Remark]</b> We <b>could</b> implement kPCA without resorting to the explicit computation of the features $\\phi(\\mathbf{x}_i)$, but the implementation is a bit tricky...\n",
    "\n",
    "This works here because the data set is not large, both in terms of input space (2-dimensional) and in the number of samples.\n",
    "    \n",
    "Remark that even with higher dimensional data set, we could simply restrict ourself to k' (principal) components, and computing the projection onto $\\mathcal{S}_k$ with k << k'.\n",
    "    \n",
    "It would be interesting for you to take advantage of this to <i>actually see what features in the feature space look like</i>.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "    \n",
    "class OutlierDetectorKPCA(OutlierDetectorPCA):\n",
    "    def __init__(self, param, k):\n",
    "        \"\"\" ------------------------------------------------------------------------------\n",
    "        Class constructor\n",
    "        INPUT:\n",
    "            - param: a dictionary containing the params of the kernel pca\n",
    "            - k: the number of eigenvectors that we keep, or equivalently, the size of the\n",
    "                 the eigen (sub)space.\n",
    "        Example of the use of the constructor\n",
    "            \n",
    "            clf_kpca = OutlierDetectorKPCA(param={'kernel':'rbf', 'gamma':42}, k=1)\n",
    "        ------------------------------------------------------------------------------ \"\"\"\n",
    "        OutlierDetectorPCA.__init__(self, k)  # we take advantage of the inheritance\n",
    "        self.kpca = KernelPCA(fit_inverse_transform=False, remove_zero_eig=False)\n",
    "        self.name = 'KPCA'\n",
    "        self.params = param\n",
    "        self.kpca.set_params(**param)\n",
    "\n",
    "    def _predict_tau_ROC(self, X, tau):\n",
    "        \"\"\" ------------------------------------------------------------------------------\n",
    "        Companion function used to properly deal with the ROC of this inherited class\n",
    "        ------------------------------------------------------------------------------ \"\"\"                \n",
    "        X_kpca = self.kpca.transform(X)\n",
    "        return OutlierDetectorPCA.predict_tau(self, X_kpca, tau)        \n",
    "        \n",
    "    def fit(self, X, y):\n",
    "        \"\"\" ------------------------------------------------------------------------------\n",
    "        Fit the model to the true data\n",
    "        INPUT: \n",
    "            - X: training data\n",
    "            - y: label of training data\n",
    "        OUTPUT:\n",
    "            - the classifier\n",
    "        ------------------------------------------------------------------------------ \"\"\"\n",
    "        X_kpca = self.kpca.fit_transform(X)\n",
    "        return OutlierDetectorPCA.fit(self, X_kpca, y)\n",
    "        \n",
    "    def get_label(self):\n",
    "        label = OutlierDetectorPCA.get_label(self) + \", gamma={gamma}, kernel={kernel}\".format(\n",
    "            gamma=self.params['gamma'],\n",
    "            kernel=self.params['kernel'])\n",
    "        return label\n",
    "        \n",
    "    def predict(self, X):\n",
    "        \"\"\" ------------------------------------------------------------------------------\n",
    "        Predict the data using the fitted model\n",
    "        INPUT: \n",
    "            - X: data\n",
    "        OUTPUT:\n",
    "            - y: predictions\n",
    "        ------------------------------------------------------------------------------ \"\"\"        \n",
    "        # TODO\n",
    "\n",
    "        y_pred = np.ones(X.shape[0])\n",
    "        return y_pred\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: you may test here your implementation of the class OutlierDetectorPCA\n",
    "\n",
    "\n",
    "# Stupid example\n",
    "k = 1\n",
    "param = {\"kernel\":\"rbf\", \"gamma\":42}\n",
    "\n",
    "clf_kpca = OutlierDetectorKPCA(param, k)\n",
    "clf_kpca.fit(X, y)\n",
    "\n",
    "\n",
    "plot_ROC(clf_kpca, X, y)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> Q5. Model selection </font> <br>\n",
    "</font>\n",
    "\n",
    "Perform your model selection: don't forget that you train your models on the train set, and tune the hyperparameter using the validation set.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# TODO: Model selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=4 color=#009999> Plot the results </font> <br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifs = [clf_kpca, clf_pca] # list of the model I want to compare\n",
    "\n",
    "plot_ROC(classifs, X, y)\n",
    "\n",
    "plot_comparison_outlier_detector(classifs, X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font size=5 color=#009999> Q6. Analysis </font> <br>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO use this cell to put your experiments that support your answer of the Q6 on your written report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
